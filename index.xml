<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Offliner&#39;s Blog</title>
    <link>https://Offliners.github.io/</link>
    <description>Recent content on Offliner&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Mon, 05 Apr 2021 21:55:10 +0800</lastBuildDate><atom:link href="https://Offliners.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>NTU - 機器學習 Week 2 - Tips for Training: Batch and Momentum</title>
      <link>https://Offliners.github.io/post/ntuml-week2-3/</link>
      <pubDate>Mon, 05 Apr 2021 21:55:10 +0800</pubDate>
      
      <guid>https://Offliners.github.io/post/ntuml-week2-3/</guid>
      <description>NTUML 2021 Spring Course Syllabus: Link
Youtube Video Link (Chinese): Video
Youtube Video Link (English): Video
Optimization with Batch 每次update參數是將每個Batch出來計算loss與gradient，將每個batch計算過後是一個epoch。每個epoch都會經過shuffle，因此每個epoch中batch的資料都不一樣
Small Batch v.s. Large Batch Large Batch 須看完每筆資料才更新參數，因此更新時間長，但每次更新很平穩
Small Batch 每看完一筆資料就更新參數，因此更新時間短，但每次更新會顯得不穩
但考慮平行運算的話，Large Batch時間不一定比Small Batch長
由上圖可知batch從1~1000所花時間差不多，但GPU仍有極限，過大的batch size仍會需要花數倍的時間
如果batch size等於1，那60000筆資料需要update參數60000次。batch size等於1000，那60000筆資料需要update參數60次。兩個每次update的時間差不多，但跑完一個epoch的差距就很大。因此考慮平行運算後，大batch size反而比較有效率
考慮平行運算後，大batch沒有時間劣勢了，且update參數比較穩定，那大batch比較好嗎?小batch比較差?
雖然在小batch size下update參數比較不穩，但有noisy的gradient反而能幫助訓練。比較上面兩資料集，小batch size的準確率比較高。那這是什麼問題呢?這是Optimization Issue
那為何小batch size沒有Optimization Issue呢?如果使用full batch size的話，走到local minima時就會停止更新參數。但如果使用small batch size的話，可能其中一個batch卡住了，但其他batch可能沒有。因此這種noisy的update參數反而對訓練比較有幫助
訓練上small batch size比較好，那測試呢?透過以上的實驗，將大batch和小batch訓練到差不多好，那比對測試時，發現小batch在測試集上表現比較好。大batch在訓練好，測試差，表示發生了overfitting。那為何會這樣呢?
假設有一個loss，有許多local minima，但local minima有分好壞，那怎麼區分好壞呢?如果local minima落在峽谷中(上圖右側)，會認為是壞minima;反之，落在平原中會是好的minima。會這樣區分是因為，測試與訓練的loss或有些差別，平原型的minima差異較小，峽谷型的minima會有較大的loss差異。而小batch因為update參數的方向都不同，容易跳出峽谷的loss，容易落在平原型的minima;對大batch來說，反而容易落在峽谷的minima
那有沒有辦法堅固兩者的優點呢?以下的論文有探討
 Large Batch Optimization for Deep Learning: Training BERT in 76 minutes (https://arxiv.</description>
    </item>
    
    <item>
      <title>NTU - 機器學習 Week 2 - Critical Point: small gradient</title>
      <link>https://Offliners.github.io/post/ntuml-week2-2/</link>
      <pubDate>Mon, 05 Apr 2021 00:38:19 +0800</pubDate>
      
      <guid>https://Offliners.github.io/post/ntuml-week2-2/</guid>
      <description>NTUML 2021 Spring Course Syllabus: Link
Youtube Video Link (Chinese): Video
Youtube Video Link (English): Video
Why Optimization fails? 有時會發現隨著參數不斷update，training的loss不再下降(藍線)，但對這loss仍不滿意。跟其他如linear model以較發現deep network沒有更好，顯然optimization有問題。有時還會發現一開始model就train不起來，不管怎麼update參數loss仍不降(紅線)。那這是發生什麼事呢?
過去的猜想是，由於模型訓練到一個地方，這地方參數對loss的微分為0，梯度下降法就沒辦法再update參數，所以loss不再下降。
說到Gradient為0，有兩種常見的可能:
 Local Minima 區域最小值 Saddle Point 鞍點 Local Maxima 區域最大值  這些會使Gradient為0的點統稱Critical point，那如果今天Gradient很接近0，那是卡在哪一個呢?等等會解說如何判斷
那又為何需要分辨卡在哪裡?如果卡在local minima那就沒路可走，但如果是saddle point那旁邊還有路可以走，可以讓loss更低。因為update參數是往低處走，所以不太會卡在local maxima
Math Method 要判斷是local minima還是saddle point呢?首先要知道loss function的形狀，由於模型通常過於複雜，使得我們無法得知loss function的全貌，但可以給定某一組參數來分析在這組參數下loss function附近的樣貌
Tayler Series Approximation 透過泰勒級數近似法可以將loss function在這組參數下分成以上三個的組合
如果今天卡在critical point，表示gradient為0，那綠色那項也為0，因此可以根據紅色那項判斷這組參數附近的error surface是長什麼樣子，進而判斷卡在哪一種critical point
為方便表示，將 $$ v = (\theta - \theta^{&#39;})$$
  紅色項帶任何值皆大於0，表示這組參數是附近的最低點，因此是local minima
  紅色項帶任何值皆小於0，表示這組參數是附近的最高點，因此是local maxima</description>
    </item>
    
    <item>
      <title>NTU - 機器學習 Week 2 - Guideline of ML: overfit</title>
      <link>https://Offliners.github.io/post/ntuml-week2-1/</link>
      <pubDate>Sat, 03 Apr 2021 23:32:44 +0800</pubDate>
      
      <guid>https://Offliners.github.io/post/ntuml-week2-1/</guid>
      <description>NTUML 2021 Spring Course Syllabus: Link
Youtube Video Link (Chinese): Video
Youtube Video Link (English): Video
Framework of ML General Guide 如果覺得訓練不滿意時，首先檢查training data的loss，看模型是否學起來再檢查testing data
有可是model bias使training data的loss無法變低。由於model過於簡單，透過訓練所有參數所得到的function set，但因為模型簡單使得function set小，因此這個function set沒有包含任何一個function使得loss變低，可以讓loss變低的function不在這個model可以描述的範圍裡面。簡單來說，想在大海裡撈針(使loss變低的function)，但針根本不在海裡，怎麼撈都撈不到。
解決方法 : 重新設計模型，使模型有更大的彈性，可以增加feature，也可以使用deep learning的方式
但不代表training時loss大就一定是model bias，有可能是optimization做不夠好
這堂課都使用梯度下降法，但這方法有些問題，如可能卡在區域最小值。如上圖藍色圖形內表示model可以表示函式的集合，這集合內確實存在loss低的function，但梯度下降法沒辦法幫我們找到他。簡單來說，想大海撈針，針確實在海裡，但我們沒辦法撈起來。
當training data的loss不夠低時，是哪個問題呢?
可以透過比較不同的模型來判斷。如果看testing data的loss表現，很多人可能覺得56層沒有比20層做得好，這是overfitting。但這不是overfitting，透過比較training data的loss，發現20層的loss比56層的低，代表56層的optimization沒有做好。這也不會是model bias的問題，56層彈性更大，一定能做到20層能做到的事，因此這就是Optimization Issue。
因此要知道optimization有沒有做好，可以先跑一些小的或是淺的模型，甚至用一些不是deep learning的方法，如Linear model或是SVM，他們比較容易做optimization。接著做深的model，如果深的model彈性大但loss沒辦法做得比淺的低，表示有Optimization Issue。以上次例子來看，模型5層出現了Optimization Issue。那要怎麼辦呢?下堂課會講解
如果已經可以讓training data的loss變小，那就可以看testing data的loss，當testing data的loss也小，那就訓練完成。
那當覺得testing data的loss還不夠小時，如果training data的loss小，testing data的loss大，那有可能遇到overfitting的問題。
舉一個極端例子，假設今天有個模型，如果輸入有出現在training data中那就輸出他的值，若沒有則輸出隨機值。此模型在training data的loss為0，但在沒看過的teating data的loss變得很大
一般情況下，假設今天實際資料呈現為二次曲線，但我們不知道，我們只能知道線上的3個點(訓練資料)，如果有個能力強的模型，彈性很大，他會通過訓練資料的三個點，但其他地方會呈現freestyle，因此丟入測試資料時會發現沒通過使loss變大
那要如何解決overfitting呢?方法一是增加訓練資料，也是最有效解決的方法。方法二是Data augmentation，如做影像辨識時，可以翻轉資料來增加資料，這Data augmentation不能隨便做，如翻轉圖片不會顛倒圖片，因為這可能不是真實世界會出現的影像。因此要根據對資料的理解，來選擇合適Data augmentation的方式
剛剛是增加資料的方式，也可以透過增加模型限制來避免overfitting。比如可以限制模型一定是二次曲線，但要如何得知呢?取決於對問題的理解。最好的是模型與資料背後產生得過程相同
如何限制模型呢?
 漸少參數、神經元，或者共用參數(CNN) 用比較少的feature Early stopping Regularization Dropout  但也不要給模型過多的限制。假設模型限制是一條直線，雖然沒辦法找到一條同時通過這三個點，但可以找到一條線loss是最低的，但這會在testing data中得到較大的loss。那這是overfitting嗎?</description>
    </item>
    
    <item>
      <title>NTU - 機器學習 Week 1 - Introduction of ML/DL</title>
      <link>https://Offliners.github.io/post/ntuml-week1/</link>
      <pubDate>Sat, 03 Apr 2021 17:05:34 +0800</pubDate>
      
      <guid>https://Offliners.github.io/post/ntuml-week1/</guid>
      <description>NTUML 2021 Spring Course Syllabus: Link
Youtube Video Link (Chinese): Video 1 Video 2
Youtube Video Link (English): Video 1 Video 2
What is Machine Learing? Q : 什麼是機器學習?
A : 機器學習簡單來說就是讓機器學會找一個函式的能力 舉例來說:
 語音辨識(Speech Recognition) : 函式輸入是聲音訊號，輸出是這段訊號的內容 影像辨識(Image Recognition) : 函式輸入是圖片，輸出是這張圖片的內容 Alpha Go : 函式輸入是棋盤上黑白棋的位置，輸出是機器下一步落子的位置  Different types of Functions  Regression : 函是輸出為純量 舉例 : 輸入今天的PM2.5濃度、溫度等，預測明天的PM2.5濃度 Classification : 給定選項，函示輸出為機器從這些選項中的選擇 舉例 : 輸入一封電子郵件，輸出為是否為垃圾郵件  Alpha Go也是一種Classification，輸入棋盤上黑白棋的位置，輸出棋盤19 * 19可以落子的位置選出下一步應該落子的位置
Q : 機器學習只有這兩個任務嗎?</description>
    </item>
    
    <item>
      <title>ORBSLAM2 Build on Windows 10</title>
      <link>https://Offliners.github.io/post/orbslam2-build/</link>
      <pubDate>Thu, 01 Apr 2021 01:31:05 +0800</pubDate>
      
      <guid>https://Offliners.github.io/post/orbslam2-build/</guid>
      <description>測試環境    Name Version     Windows 10 x64   OpenCV 3.4.1   Visual Studio 2015   CMake 3.20     OpenCV : Install Link Visual Studio 2015 : Install Link CMake : Install Link  記得將YOUR_OWN_PATH\opencv\build\x64\vc14\bin與YOUR_OWN_PATH\opencv\build新增至環境變數中，資料夾路徑視OpenCV的安裝目錄而定
安裝ORBSLAM2 for Windows 下載 ORBSLAM2 Download : Link
安裝DBoW2 使用Cmake-gui將Source code路徑選.\orbslam-windows\Thirdparty\DBoW2，而binaries選擇.\orbslam-windows\Thirdparty\DBoW2\build，若沒有build資料夾程式可以自動建立
接著按Configure選擇Visual Studio 14 2015，平台選擇x64或是你的作業系統而定
按下finish開始編譯，Configuring done後選擇Generate，等Generating done後按Open Project開啟VS
進入Visual Studio 2015後，先將Mode選擇Release，接著對DBoW2按右鍵選擇Properties，將Target Extension的.dll改成.lib，還有Configuration Type改成Static library(.</description>
    </item>
    
    <item>
      <title>[110學年度] 台清交推甄心得</title>
      <link>https://Offliners.github.io/post/110%E5%AD%B8%E5%B9%B4%E5%BA%A6-%E5%8F%B0%E6%B8%85%E4%BA%A4%E6%8E%A8%E7%94%84%E5%BF%83%E5%BE%97/</link>
      <pubDate>Tue, 30 Mar 2021 22:23:42 +0800</pubDate>
      
      <guid>https://Offliners.github.io/post/110%E5%AD%B8%E5%B9%B4%E5%BA%A6-%E5%8F%B0%E6%B8%85%E4%BA%A4%E6%8E%A8%E7%94%84%E5%BF%83%E5%BE%97/</guid>
      <description>個人基本資料  學校 : 國立臺灣師範大學  主修 : 機電工程學系 雙主修 : 電機工程學系   在校成績 : 系排 2 (4%) 平均 GPA : 4.15 (學分數: 142) 社團經歷  第二屆機電營 美輔股 股員 第三屆機電營 場器股 股長 第四屆機電營 美輔股 培訓講師 第四屆機電營 場器股&amp;amp;課程股電路組 股長 機電工程系學會 家長股長 全校英語讀書會成果發表 第三名   教學助理經驗  程式設計 數位邏輯實驗 感測器原理與應用   實習  工業局 108 年度智慧機器人才培育 桃園協易機械 - 沖壓機械智能感測產學專案實習 桃園協易機械實習培訓 - LabVIEW講師    各系所申請人數與錄取人數  109學年度     系所 錄取人數 申請人數 錄取率     台大電機所甲組 20 110 18.</description>
    </item>
    
    <item>
      <title>Anaconda Virtual Environment Use tensorflow-gpu</title>
      <link>https://Offliners.github.io/post/anaconda-virtualenv-use-tensorflow-gpu/</link>
      <pubDate>Tue, 30 Mar 2021 22:19:35 +0800</pubDate>
      
      <guid>https://Offliners.github.io/post/anaconda-virtualenv-use-tensorflow-gpu/</guid>
      <description>測試環境 作業系統 : Window 10 64bit
顯卡 : NVIDIA Geforce GTX 1050
事前準備 1. 確認電腦是否有NVIDIA顯卡 可以從裝置管理員中顯示卡看電腦是否有NVIDIA顯卡
2. 查詢此顯卡的計算能力 可從此網址查詢到 : https://developer.nvidia.com/cuda-gpus
建議顯卡計算能力(Compute Capability) 大於3.5以上，使用tensorflow-gpu才會有明顯的成效
安裝步驟 1. 安裝Anaconda 到Anaconda官方網站下載 : https://www.anaconda.com/products/individual
安裝一直next過去就好
2. 打開Anaconda Prompt 3. 建立虛擬環境 在命令列輸入conda create -n test_env pip python=3.6，test_env是環境名稱，可以自己取，然後Python的版本是3.6
這裡輸入y
4. 進入虛擬環境 建立完成後，輸入activate test_env進入虛擬環境
當前方出現自己的環境名稱表示進入成功
5. 安裝tensorflow-gpu 輸入pip install tensorflow-gpu==1.13.1，安裝版本為1.13.1的tensorflow-gpu
6. 安裝 CUDA 10.0 進入此網站 : https://developer.nvidia.com/cuda-toolkit-archive
尋找CUDA 10.0並安裝
一直按下一步就安裝完成
確認是否有加入環境變數，在Window搜尋環境變數
CUDA安裝軟體基本上會自動填入路徑
安裝cuDNN 7.6.5 進入此網站 : https://developer.nvidia.com/rdp/cudnn-archive</description>
    </item>
    
    <item>
      <title>使用 Hugo 在 Github Pages 建立靜態網站</title>
      <link>https://Offliners.github.io/post/hugo-first/</link>
      <pubDate>Tue, 30 Mar 2021 21:19:31 +0800</pubDate>
      
      <guid>https://Offliners.github.io/post/hugo-first/</guid>
      <description>Hugo 簡介 Hugo 是使用Go語言編寫的靜態網頁生成器，基於Go語言開發，沒有像HTML5錯綜複雜的依賴關係。除此之外，還擁有活躍的社群提供多樣主題與完善的功能給使用者，支援多種類的前端語言，整體架構也靈活易懂，最大優點是編譯速度極快，建立網站時間平均不到1秒種，使用者修改時能即時預覽。
Hugo 安裝  MacOS &amp;amp; Linux  MacOS使用者可使用Homebrew安裝
brew install hugo  Window  Window使用者須視使用者環境下載適用的版本 https://github.com/gohugoio/hugo/releases 或者透過chocolatey安裝
choco install hugo -confirm 安裝好後再去設定環境變數，例如: C:\hugo，記得將hugo.exe放進此路徑資料夾中
Hugo 指令測試 安裝好後透過CMD輸入hugo version可查看版本
hugo v0.81.0-59D15C97 linux/amd64 BuildDate=2021-02-19T17:07:12Z VendorInfo=gohugoio 建立 Project 透過CMD輸入
hugo new site mysite 則會在此路徑下建立mysite的資料夾，mysite可換任意名稱 資料夾結構如下:
mysite/ │ ├── archetypes/ │ │ │ └─ default.md # 預設 markdown ├── content/ # 頁面、文章（markdown） ├── data/ # 資料庫 ├── layouts/ # 自定義的樣板 ├── static/ # 靜態資源 ├── themes/ # 網站的主題 └── config.</description>
    </item>
    
    <item>
      <title>ABOUT</title>
      <link>https://Offliners.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Offliners.github.io/about/</guid>
      <description>Hi there, l&amp;rsquo;m Offliner. </description>
    </item>
    
  </channel>
</rss>
