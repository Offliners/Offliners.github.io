<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Offliner&#39;s Blog - NTU - 機器學習 Week 7 - Transformer </title>
    
    
    <meta content="Machine Learning, Deep Learning, NTU ML 2021, NTU 機器學習 note" name="keywords">
    
    <meta content="Offliner&#39;s Blog - NTUML 2021 Spring Course Syllabus: Link
Youtube Video Link (Chinese): Video 1 Video 2
Youtube Video Link (English): Video 1 Video 2
Applications of Sequence-to-sequence (Seq2seq) 當模型輸入是sequence時，輸出可以是與輸入相同長度的sequence，也可能是未知長度的sequence，由機器去決定。輸出是未知長度sequence的例子如
 語音辨識 Speech Recognition 機器翻譯 Machine Translation 語音翻譯 Speech Translation  這時可能有人問為何要做語音翻譯?直接語音辨識再機器翻譯不就好了?因為世界上有眾多語言，有些語言甚至連文字都沒有，沒有文字的語言難以做語音辨識
若想了解台語語音辨識可點以下連結: To learn more : Link
輸入聲音，輸出辨識後的文字是語音辨識 Speech Recognition。反過來，輸入文字，輸出聲音訊號，就是語音合成 Text-to-Speech Synthesis
Seq2seq for Chatbot 文字方面，也可透過使用Seq2seq的模型來訓練，例如可以訓練聊天機器人，輸入輸出都是文字，訓練資料是一堆對話的內容
Most Natural Language Processing applications 很多NLP的問題可以看成是QA的問題，多數QA的問題又可以透過Seq2seq解決。輸入問題與文章，輸出就是問題的答案
想了解更多NLP的處理，可參考以下連結 To learn more :
 The Natural Language Decathlon: Multitask Learning as Question Answering : Link LAMOL: LAnguage MOdeling for Lifelong Language Learning : Link DEEP LEARNING FOR HUMAN LANGUAGE PROCESSING 2020 SPRING : Link  Seq2seq for Syntactic Parsing Seq2seq也可用於文法剖析，輸入是一段文字，但輸出就不是sequence，而是樹狀結構用來分析各文字的組成" name="description">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    
        <link rel="icon" href="/images/dino.png">
    

    

    
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-WFQ2VM3C00"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments)};
          gtag('js', new Date());
          gtag('config', 'G-WFQ2VM3C00');
        </script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            extensions: ["tex2jax.js"],
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: true
            },
            "HTML-CSS": { availableFonts: ["TeX"] }
        });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>
    

    <link rel="stylesheet" href="/layui/css/layui.css">
    <link rel="stylesheet" href="/self/css/default.css">
    <script src=" /layui/layui.js"></script>

    <link rel="stylesheet" async href="/self/css/markdown.min.css">
    <link rel="stylesheet" async href="/self/css/gallery.css">
    
    
    

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
    <script async src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.0/lazysizes.min.js" integrity="sha256-h2tMEmhemR2IN4wbbdNjj9LaDIjzwk2hralQwfJmBOE=" crossorigin="anonymous"></script></head>

<body>
    
    <header class="layui-header layui-bg-cyan">

    
        <a href=""><img src="/images/Offliner.png" class="layui-nav-img" style="margin-left:10px;margin-top:-10px"></a>
    
    
    <a class="nav-self-logo" href="/">
        Offliner&#39;s Blog
    </a>

    <ul class="layui-nav layui-layout-right layui-bg-cyan" lay-filter="">
        
        
        <li class="layui-nav-item" id="nav_big"><a href="/post/">Posts</a></li>
        

        
            
                <li class="layui-nav-item" id="nav_big"><a href="/zone/">Archives</a></li>
            
                <li class="layui-nav-item" id="nav_big"><a href="/about/">About</a></li>
            
                <li class="layui-nav-item" id="nav_big"><a href="/">Home</a></li>
            
        

        
        <li class="layui-nav-item" id="nav_small">
            <a href="javascript:;">
                <i class="layui-icon layui-icon-app" style="font-size: 24px;"></i>
            </a>

            <dl class="layui-nav-child">
                
                <dd><a href="/post/">Posts</a></dd>
                

                
                    
                        <dd><a href="/zone/">Archives</a></dd>
                    
                        <dd><a href="/about/">About</a></dd>
                    
                        <dd><a href="/">Home</a></dd>
                    
                
            </dl>
        </li>
    </ul>
</header>

<script>
layui.use('element', function(){
  var element = layui.element;
});
</script>

        <div id="content" style="min-height:80%">
<div class="layui-container" style="margin-bottom: 10px">
    
    <div class="layui-row layui-col-space10">
        <div class="layui-col-md8 layui-col-sm12 layui-col-xs12">
            <div class="layui-card single-card">
                <br />
                <blockquote class="self-elem-quote self-elem-quote-bg-red markdown-body single-title" >
                    <h1>NTU - 機器學習 Week 7 - Transformer</h1>
                    <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>2021-04-13</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/ntu-%e6%a9%9f%e5%99%a8%e5%ad%b8%e7%bf%92-note/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU 機器學習 note</span>
        </a>
    

    
    <i class="layui-icon layui-icon-tabs" style="font-size: 22px; vertical-align: 1px;margin-right:2px;"></i>
    

    
        <a href="/tags/machine-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Machine Learning</span>
        </a>
    
        <a href="/tags/deep-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Deep Learning</span>
        </a>
    
        <a href="/tags/ntu-ml-2021/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU ML 2021</span>
        </a>
    
    
</h3>

                </blockquote>
                <div class="layui-card-body markdown-body single-content">
                    <p><img src="/2021NTUML/Week7/cover-1.JPG" alt="cover 1"></p>
<p>NTUML 2021 Spring Course Syllabus: <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html">Link</a></p>
<p>Youtube Video Link (Chinese): <a href="https://www.youtube.com/watch?v=n9TlOhRjYoc"><code>Video 1</code></a> <a href="https://youtu.be/N6aRv06iv2g"><code>Video 2</code></a></p>
<p>Youtube Video Link (English): <a href="https://www.youtube.com/watch?v=zmOuJkH9l9M"><code>Video 1</code></a> <a href="https://www.youtube.com/watch?v=fPTj5Zh1ACo"><code>Video 2</code></a></p>
<h2 id="applications-of-sequence-to-sequence-seq2seq">Applications of Sequence-to-sequence (Seq2seq)</h2>
<p><img src="/2021NTUML/Week7/seq2seq.JPG" alt="Sequence-to-sequence">
當模型輸入是sequence時，輸出可以是與輸入相同長度的sequence，也可能是未知長度的sequence，由機器去決定。輸出是未知長度sequence的例子如</p>
<ul>
<li>語音辨識 Speech Recognition</li>
<li>機器翻譯 Machine Translation</li>
<li>語音翻譯 Speech Translation</li>
</ul>
<p>這時可能有人問為何要做語音翻譯?直接語音辨識再機器翻譯不就好了?因為世界上有眾多語言，有些語言甚至連文字都沒有，沒有文字的語言難以做語音辨識</p>
<p>若想了解台語語音辨識可點以下連結:
To learn more : <a href="https://sites.google.com/speech.ntut.edu.tw/fsw/home/challenge-2020">Link</a></p>
<p>輸入聲音，輸出辨識後的文字是<code>語音辨識 Speech Recognition</code>。反過來，輸入文字，輸出聲音訊號，就是<code>語音合成 Text-to-Speech Synthesis</code></p>
<h3 id="seq2seq-for-chatbot">Seq2seq for Chatbot</h3>
<p><img src="/2021NTUML/Week7/chatbot.JPG" alt="Seq2seq for Chatbot">
文字方面，也可透過使用Seq2seq的模型來訓練，例如可以訓練聊天機器人，輸入輸出都是文字，訓練資料是一堆對話的內容</p>
<h3 id="most-natural-language-processing-applications">Most Natural Language Processing applications</h3>
<p><img src="/2021NTUML/Week7/NLP.JPG" alt="Most Natural Language Processing applications">
很多NLP的問題可以看成是QA的問題，多數QA的問題又可以透過Seq2seq解決。輸入問題與文章，輸出就是問題的答案</p>
<p>想了解更多NLP的處理，可參考以下連結
To learn more :</p>
<ul>
<li>The Natural Language Decathlon: Multitask Learning as Question Answering : <a href="https://arxiv.org/abs/1806.08730">Link</a></li>
<li>LAMOL: LAnguage MOdeling for Lifelong Language Learning : <a href="https://arxiv.org/abs/1909.03329">Link</a></li>
<li>DEEP LEARNING FOR HUMAN LANGUAGE PROCESSING 2020 SPRING : <a href="https://speech.ee.ntu.edu.tw/~hylee/dlhlp/2020-spring.html">Link</a></li>
</ul>
<h3 id="seq2seq-for-syntactic-parsing">Seq2seq for Syntactic Parsing</h3>
<p><img src="/2021NTUML/Week7/syntacticparsing-1.JPG" alt="Seq2seq for Syntactic Parsing">
Seq2seq也可用於文法剖析，輸入是一段文字，但輸出就不是sequence，而是樹狀結構用來分析各文字的組成</p>
<p><img src="/2021NTUML/Week7/syntacticparsing-2.JPG" alt="Seq2seq for Syntactic Parsing">
不過樹狀結構也可以看成是一段sequence，這樣就可以套用Seq2seq來處理</p>
<p>To learn more :</p>
<ul>
<li>Grammar as a Foreign Language : <a href="https://arxiv.org/abs/1412.7449">Link</a></li>
</ul>
<h3 id="seq2seq-for-multi-label-classification">Seq2seq for Multi-label Classification</h3>
<p><img src="/2021NTUML/Week7/multilabel.JPG" alt="Seq2seq for Multi-label Classification">
首先要區分<code>Multi-label Classification</code> 與<code>Multi-class Classification</code>。Multi-class Classification是多個class由機器去選擇一個，Multi-label Classification是指同一個東西但屬於可能有多個class。那要怎麼處理Multi-label Classification的問題呢?可以透過Seq2seq，比如輸入文章，輸出是他所屬於的class</p>
<p>To learn more :</p>
<ul>
<li>Order-free Learning Alleviating Exposure Bias in Multi-label Classification : <a href="https://arxiv.org/abs/1909.03434">Link</a></li>
<li>Order-Free RNN with Visual Attention for Multi-Label Classification : <a href="https://arxiv.org/abs/1707.05495">Link</a></li>
</ul>
<h3 id="seq2seq-for-object-detection">Seq2seq for Object Detection</h3>
<p><img src="/2021NTUML/Week7/object.JPG" alt="Seq2seq for Object Detection">
甚至連物件偵測也能透過Seq2seq來解決</p>
<p>To learn more :</p>
<ul>
<li>End-to-End Object Detection with Transformers : <a href="https://arxiv.org/abs/2005.12872">Link</a></li>
</ul>
<h2 id="seq2seq">Seq2seq</h2>
<p><img src="/2021NTUML/Week7/seq2seq-1.JPG" alt="Seq2seq">
一般的Seq2seq會由encoder與decoder組成，上圖是Seq2seq早期的架構</p>
<p>To learn more :</p>
<ul>
<li>Sequence to Sequence Learning with Neural Networks : <a href="https://arxiv.org/abs/1409.3215">Link</a></li>
</ul>
<p><img src="/2021NTUML/Week7/transformer.JPG" alt="Transformer">
現今主流架構會是<code>Transformer</code></p>
<h2 id="encoder">Encoder</h2>
<p><img src="/2021NTUML/Week7/encoder.JPG" alt="Encoder">
Encoder在做的事情是輸入一排向量，輸出也是一排向量。Transformer中的encoder就是self-attention，透過下圖來簡單介紹</p>
<p><img src="/2021NTUML/Week7/transformer-1.JPG" alt="Transformer Emcoder 1">
上圖每個block都是輸入一排向量，輸出一排向量。而block中會先對輸入做self-attention，接著送入fully connected network中，最後就是輸出的向量</p>
<p><img src="/2021NTUML/Week7/transformer-2.JPG" alt="Transformer Emcoder 2">
而實際的Transformer中，會把self-attention輸出的向量加上原本的輸入，這樣的行為叫做<code>Residual</code>。接著會把residual後的向量做<code>Layer Normalization</code>，不同於Batch Normalization的是Batch Normalization是對同一個維度不同的feature做計算，但Layer Normalization不同的維度同一個的feature做計算。做完Layer Normalization得到的輸出就會是fully connected network的輸入，這裡也會套用residual與Layer Normalization的架構</p>
<p><img src="/2021NTUML/Week7/transformer-3.JPG" alt="Transformer Emcoder 3">
上述介紹的簡易模型也就是Transformer encoder中block處理的方式，而這複雜的block再之後會介紹的BERT也會用到</p>
<p>若想了解更多為何要這樣encoder，可參考以下連結
To learn more :</p>
<ul>
<li>On Layer Normalization in the Transformer Architecture : <a href="https://arxiv.org/abs/2002.04745">Link</a></li>
<li>PowerNorm: Rethinking Batch Normalization in Transformers : <a href="https://arxiv.org/abs/2003.07845">Link</a></li>
</ul>
<h2 id="decoder">Decoder</h2>
<p><img src="/2021NTUML/Week7/decoder.JPG" alt="Decoder">
Decoder有分兩種:</p>
<ul>
<li>Autoregressive (AT)</li>
<li>Non-autoregressive (NAT)</li>
</ul>
<h3 id="autoregressive">Autoregressive</h3>
<p><img src="/2021NTUML/Week7/autoregressive.JPG" alt="Autoregressive">
如果是語音辨識，那會將聲音訊號輸入至encoder，輸出會是一排向量，接著這些向量會輸入到deocder來產生語音辨識的結果。那decoder是怎麼處理的呢?首先要有個特殊符號begin，通常是個one-hot vector，然後decoder會輸出一個向量，這個向量長度是自行定義的，假設是做中文的語音辨識，那向量長度可能就會是中文方塊字的數目，由於這向量通常會經過softmax產生，所以會把向量中分數最高的當成輸出，會由one-hot vector表示</p>
<p><img src="/2021NTUML/Week7/autoregressive-1.JPG" alt="Autoregressive 1">
接著將剛剛輸出的one-hot vector與begin當成decoder的輸入，就會輸出向量中得分最高的值再用one-hot vector，接著再將begin與兩個one-hot vector輸入至decoder，又得到一個新的one-hot vector，以此類推。簡言之，decoder會將自己的輸出當成下一個自己的輸入，因此decoder辨識錯誤時，就可能會輸入錯的東西，那這樣會不會造成Error Propagation的問題?有可能，等等會說解決方法</p>
<p><img src="/2021NTUML/Week7/decoder-1.JPG" alt="Decoder 1">
上圖為deocder在Transformer中的結構</p>
<p><img src="/2021NTUML/Week7/vs.JPG" alt="Encoder v.s Decoder">
比較Transformer中的encoder與decoder，可以發現如果將decoder的紅色區域拿掉，兩者無太大差異，然後decoder會再經過softmax來產生機率。但可以發現decoder不同於encoder，是Multi-head Attention變成<code>Masked Multi-head Attention</code></p>
<p><img src="/2021NTUML/Week7/self.JPG" alt="Self-attention">
原本的Self-attention每個輸出需要看過每一個輸入才做決定</p>
<p><img src="/2021NTUML/Week7/masked-self.JPG" alt="Masked Self-attention">
但Masked Self-attention變成輸出只看輸入左側的向量來決定，不看右側，所以只有最後一個輸出會考慮整個輸入才決定</p>
<p><img src="/2021NTUML/Week7/self-1.JPG" alt="Self-attention 1">
可以比較兩者的計算，上圖是Self-attention的計算方式，若要計算出b2，q2需要拿a1~a4的key</p>
<p><img src="/2021NTUML/Week7/masked-self-1.JPG" alt="Masked Self-attention 1">
如果是Masked Self-attention，若要計算出b2，q2只能拿a1、a2的key。那為何要不用Self-attention而是Masked Self-attention呢?</p>
<p>其實很直覺，思考剛剛提到的decoder的運作方式是逐一產生的，輸入的資料只有自己以前的，因此沒辦法參考全部的資訊</p>
<p><img src="/2021NTUML/Week7/decoder-2.JPG" alt="Decoder 2">
但decoder還有個關鍵的問題，就是decoder需要決定輸出sequence的長度</p>
<p><img src="/2021NTUML/Week7/decoder-3.JPG" alt="Decoder 3">
為了能讓decoder能停下來，需要一個特殊符號</p>
<p><img src="/2021NTUML/Week7/decoder-4.JPG" alt="Decoder 4">
因此預期當機器讀到最後一個輸入時，能讀到這個特殊符號來停止輸出</p>
<h3 id="non-autoregressive">Non-autoregressive</h3>
<p><img src="/2021NTUML/Week7/NAT.JPG" alt="Non-autoregressive">
autoregressive是輸入begin，接著輸出w1，再把begin與w1當成輸入，直到輸出到end為止。Non-autoregressive不是一次產生一個詞，而是一次產生整個句子，因此一次輸入多個begin來產生整個句子。那這樣NAT要輸入多少begin來決定句子的長度?有兩種做法，第一種是定義另一個模型來預測句子輸出的長度，這個模型的輸出會是一個數值。另一種方法是直接輸入自行定義的句子長度上限，接著當輸出有end時，右邊的部分就都捨棄。</p>
<p>那NAT相較於AT有什麼好處呢?</p>
<ul>
<li>平行化，句子能一次產生</li>
<li>能控制輸出句子的長度</li>
</ul>
<p>雖然NAT有很多優勢，但目前NAT的表現是差於AT，由於NAT有著<code>Multi-modality</code>的問題，若想瞭解更多關於NAT的資訊可以參考以下連結:</p>
<ul>
<li>Non-Autoregressive Sequence Generation : <a href="https://youtu.be/jvyKmU4OM3c">Link</a></li>
</ul>
<h2 id="encoder---decoder">Encoder - Decoder</h2>
<p><img src="/2021NTUML/Week7/encoder-decoder.JPG" alt="Encoder - Decoder">
那encoder與decoder怎傳遞資訊?接著要來講解剛剛Transform中紅色的區域<code>Cross Attention</code>，上圖可以發現Cross attention有兩個輸入來自encoder，一個來自decoder</p>
<p><img src="/2021NTUML/Week7/crossattention.JPG" alt="Cross attention">
Cross attention是將由encoder產生k、v，由decoder產生q，來產生decoder接下來fully connected network輸入的資訊</p>
<p><img src="/2021NTUML/Week7/crossattention-1.JPG" alt="Cross attention 1">
decoder接下來的輸入也是經過相同的Cross attention計算</p>
<p><img src="/2021NTUML/Week7/crossattention-2.JPG" alt="Cross attention 2">
上圖灰階的部分是Cross attention的得分，此實驗來自以下論文</p>
<ul>
<li>Listen, attend and spell: A neural network for large vocabulary conversational speech recognition : [Link](Listen, attend and spell: A neural network for large vocabulary conversational speech recognition)</li>
</ul>
<p><img src="/2021NTUML/Week7/crossattention-3.JPG" alt="Cross attention 3">
但encoder與decoder有很多層，decoder只能拿encoder最後一層的輸出嗎?原始論文的實作是這麼做，但實際上可以有不同的連接方式</p>
<p>原始論文的連結:</p>
<ul>
<li>Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning : <a href="https://arxiv.org/abs/2005.08081">Link</a></li>
</ul>
<h2 id="training">Training</h2>
<p><img src="/2021NTUML/Week7/training.JPG" alt="Training">
首先透過人工Label的方式，將聽到的聲音訊號標記Label，這些Label也是希望機器能產生的，機器會透過decoder的輸出，來產生分布的機率並選取機率最高的字當成輸出，因此這也是個分類的問題</p>
<p><img src="/2021NTUML/Week7/training-1.JPG" alt="Training 1">
值得注意的是，decoder的輸入其實就是正確答案，這叫做<code>Teacher Forcing</code>，訓練時會輸入正確答案，但測試時沒有，因為deocder會看到自己的輸入，那這之間會有個mismatch，等等會介紹解決方式</p>
<h2 id="tips-of-training-seq2seq">Tips of Training Seq2seq</h2>
<h3 id="copy-mechanism">Copy Mechanism</h3>
<p><img src="/2021NTUML/Week7/copy.JPG" alt="Copy Mechanism">
剛剛的介紹都是deocder自己產生輸出，但對很多任務而言，decoder沒必要自己產生輸出，而是從輸入複製一些東西出來。這種行為可以用Chatbot，例如對於名稱或者對於機器不懂的話，機器不需要再重頭創造，只需要從輸入去複製作為輸出</p>
<p><img src="/2021NTUML/Week7/summary.JPG" alt="Copy Mechanism 1">
或者是做摘要的時候，可以透過輸入文章給機器，機器會輸出這個文章的摘要。摘要中有許多的詞彙是直接從原文章中複製出來的，若想了解Seq2seq如何做到可以參考以下連結</p>
<ul>
<li>Pointer Network : <a href="https://youtu.be/VdOyqNQ9aww">Video</a></li>
<li>Incorporating Copying Mechanism in Sequence-to-Sequence Learning : <a href="https://arxiv.org/abs/1603.06393">Link</a></li>
</ul>
<h3 id="guild-attention">Guild Attention</h3>
<p><img src="/2021NTUML/Week7/guide.JPG" alt="Guild Attention">
有時候訓練Seq2seq的模型，會發現機器會漏字或漏看一些資訊，因此可以透過<code>Guild Attention</code>強迫機器一定要把每個東西都看過，Guild Attention會要求機器在做Attention時有固定的方式。假設做語音合成時，由於聲音訊號是由左到右，因此做Attention時應該也要由左到右，但如果發現attention是隨機的，那可能會出現一些錯誤</p>
<h3 id="beam-search">Beam Search</h3>
<p><img src="/2021NTUML/Week7/beam.JPG" alt="Beam Search">
假設decoder只能產生兩個字A、B，decoder會選擇分數最高的，再把分數高的當成decoder的輸入再選擇分數高的當成輸出，這樣的流程叫<code>Greedy Decoding</code>。那這是最好的方法嗎?有沒有可能第一步雖然選擇低的，但第二步的得分更高?</p>
<p>若要找到最佳路徑要怎找?窮舉法太多可能性會行不通，因此可以透過<code>Beam Search</code>使用較有效的方法尋找可能解</p>
<p><img src="/2021NTUML/Week7/beam-1.JPG" alt="Beam Search 1">
那Beam Search是否有用呢?有個論文是做Sentence Completion，機器讀入一段句子並由機器完成後半段，使用Beam Search時會發現機器不斷講重複的話(左)。若用其他方法，加入一些隨機性可發現結果雖然沒有很好，但會輸出一些較正常的句子(右)。因此對decoder而言，不見得分數最高的路是最好的，因此這要取決於任務本身的特性。假設任務答案非常明確，Beam Search會比較有幫助。但如果需要機器有些創造力時，Beam Search就表現比較差，這種問題往往需要在decoder加入隨機性，這非常神奇因為在decoder加入noise違背正常ML會做的想法，訓練時加入雜訊使機器看更多可能性是好的，但在測試時加入雜訊使測試狀況更複雜會使表現變差，但如Sentence Completion、TTS(Text-to-speech)等問題測試時加入隨機性反而表現比較好</p>
<h3 id="optimizing-evaluation-metrics">Optimizing Evaluation Metrics</h3>
<p><img src="/2021NTUML/Week7/BLEU.JPG" alt="Optimizing Evaluation Metrics">
在評估deocder時常用<code>BLEU score</code>，計算方式是將decoder輸出的整個句子與正確答案做比較去計算出BLEU score。但在訓練時不是這樣，訓練時是將詞彙分開考慮去minimize cross-entropy，由於訓練與測試的評分標準不同，因此minimize cross-entropy不見得能minimize BLEU score。那能在訓練時使用BLEU score?不能，因為BLEU score無法微分，如果把BLEU score當成loss無法算gradient</p>
<p>若在Optimization無法解決的問題，可以透過RL(Reinforcement Learning)來解決，可以參考以下連結</p>
<ul>
<li>Sequence Level Training with Recurrent Neural Networks : <a href="https://arxiv.org/abs/1511.06732">Link</a></li>
</ul>
<p><img src="/2021NTUML/Week7/mismatch.JPG" alt="Exposure Bias">
那訓練與測試不一致，測試時decoder看到自己的輸出，因此有可能看到錯誤的東西，但訓練時decoder是看到正確答案，這個不一致的現象叫<code>Exposure Bias</code>，那要怎麼解決呢?可以在訓練時給decoder看一些錯誤的東西，不要一直給decoder看正確答案</p>
<p><img src="/2021NTUML/Week7/schedule.JPG" alt="Scheduled Sampling">
而這種方法叫<code>Scheduled Sampling</code>，但這會傷害到Transformer平行化的能力，因此不同的Seq2seq模型有不同Scheduled Sampling的方法，想了解更多可參考以下連結:</p>
<ul>
<li>Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks : <a href="https://arxiv.org/abs/1506.03099">Link</a></li>
<li>Scheduled Sampling for Transformers : <a href="https://arxiv.org/abs/1906.07651">Link</a></li>
<li>Parallel Scheduled Sampling : <a href="https://arxiv.org/abs/1906.04331">Link</a></li>
</ul>
</div>
            </div>
            
                <script src="https://utteranc.es/client.js"
                    repo="Offliners/MyBlogComments"
                    issue-term="pathname"
                    theme="github-light"
                    crossorigin="anonymous"
                    async>
                </script>
            
        </div>

        <div class="layui-col-md4 layui-col-sm12 layui-col-xs12">
            
            <div class="layui-card single-card">
                <h2 class="single-title">- Table of Contents -</h2>
                <div style="margin-left: 10px;">   
                    <div>

<ul class="toc-h2"><li><a href="/post/ntuml-week7-1/#applications-of-sequence-to-sequence-seq2seq">Applications of Sequence-to-sequence (Seq2seq)</a></li>
            <li><a href="/post/ntuml-week7-1/#seq2seq">Seq2seq</a></li>
            <li><a href="/post/ntuml-week7-1/#encoder">Encoder</a></li>
            <li><a href="/post/ntuml-week7-1/#decoder">Decoder</a></li>
            <li><a href="/post/ntuml-week7-1/#encoder---decoder">Encoder - Decoder</a></li>
            <li><a href="/post/ntuml-week7-1/#training">Training</a></li>
            <li><a href="/post/ntuml-week7-1/#tips-of-training-seq2seq">Tips of Training Seq2seq</a></li>
            </div>
                </div>
            </div>
            

            
            <div class="layui-card single-card">
                <h2 class="single-title">- Relevant Topics -</h2>
                
                	
                    <div style="margin-left: 10px;">
                        <blockquote class="self-elem-quote self-elem-quote-bg-red" style="background-color:#FFFFFF;margin-top: 10px;">
                            <a href="/post/ntuml-week5-2/">
                                <h3 class="">NTU - 機器學習 Week 5 - Normalization</h3>
                            </a>
                            <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>2021-04-11</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/ntu-%e6%a9%9f%e5%99%a8%e5%ad%b8%e7%bf%92-note/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU 機器學習 note</span>
        </a>
    

    
    <i class="layui-icon layui-icon-tabs" style="font-size: 22px; vertical-align: 1px;margin-right:2px;"></i>
    

    
        <a href="/tags/machine-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Machine Learning</span>
        </a>
    
        <a href="/tags/deep-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Deep Learning</span>
        </a>
    
        <a href="/tags/ntu-ml-2021/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU ML 2021</span>
        </a>
    
    
</h3>

                        </blockquote>
                    </div>
                	
                    <div style="margin-left: 10px;">
                        <blockquote class="self-elem-quote self-elem-quote-bg-red" style="background-color:#FFFFFF;margin-top: 10px;">
                            <a href="/post/ntuml-week5-1/">
                                <h3 class="">NTU - 機器學習 Week 5 - Self-Attention</h3>
                            </a>
                            <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>2021-04-10</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/ntu-%e6%a9%9f%e5%99%a8%e5%ad%b8%e7%bf%92-note/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU 機器學習 note</span>
        </a>
    

    
    <i class="layui-icon layui-icon-tabs" style="font-size: 22px; vertical-align: 1px;margin-right:2px;"></i>
    

    
        <a href="/tags/machine-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Machine Learning</span>
        </a>
    
        <a href="/tags/deep-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Deep Learning</span>
        </a>
    
        <a href="/tags/ntu-ml-2021/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU ML 2021</span>
        </a>
    
    
</h3>

                        </blockquote>
                    </div>
                	
                    <div style="margin-left: 10px;">
                        <blockquote class="self-elem-quote self-elem-quote-bg-red" style="background-color:#FFFFFF;margin-top: 10px;">
                            <a href="/post/ntuml-week3-3/">
                                <h3 class="">NTU - 機器學習 Week 3 - CNN</h3>
                            </a>
                            <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>2021-04-08</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/ntu-%e6%a9%9f%e5%99%a8%e5%ad%b8%e7%bf%92-note/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU 機器學習 note</span>
        </a>
    

    
    <i class="layui-icon layui-icon-tabs" style="font-size: 22px; vertical-align: 1px;margin-right:2px;"></i>
    

    
        <a href="/tags/machine-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Machine Learning</span>
        </a>
    
        <a href="/tags/deep-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Deep Learning</span>
        </a>
    
        <a href="/tags/ntu-ml-2021/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU ML 2021</span>
        </a>
    
    
</h3>

                        </blockquote>
                    </div>
                	
                    <div style="margin-left: 10px;">
                        <blockquote class="self-elem-quote self-elem-quote-bg-red" style="background-color:#FFFFFF;margin-top: 10px;">
                            <a href="/post/ntuml-week3-2/">
                                <h3 class="">NTU - 機器學習 Week 3 - Loss Function: Classification</h3>
                            </a>
                            <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>2021-04-06</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/ntu-%e6%a9%9f%e5%99%a8%e5%ad%b8%e7%bf%92-note/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU 機器學習 note</span>
        </a>
    

    
    <i class="layui-icon layui-icon-tabs" style="font-size: 22px; vertical-align: 1px;margin-right:2px;"></i>
    

    
        <a href="/tags/machine-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Machine Learning</span>
        </a>
    
        <a href="/tags/deep-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Deep Learning</span>
        </a>
    
        <a href="/tags/ntu-ml-2021/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU ML 2021</span>
        </a>
    
    
</h3>

                        </blockquote>
                    </div>
                	
                    <div style="margin-left: 10px;">
                        <blockquote class="self-elem-quote self-elem-quote-bg-red" style="background-color:#FFFFFF;margin-top: 10px;">
                            <a href="/post/ntuml-week3-1/">
                                <h3 class="">NTU - 機器學習 Week 3 - Tips for Training: Adaptive Learning Rate</h3>
                            </a>
                            <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>2021-04-06</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/ntu-%e6%a9%9f%e5%99%a8%e5%ad%b8%e7%bf%92-note/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU 機器學習 note</span>
        </a>
    

    
    <i class="layui-icon layui-icon-tabs" style="font-size: 22px; vertical-align: 1px;margin-right:2px;"></i>
    

    
        <a href="/tags/machine-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Machine Learning</span>
        </a>
    
        <a href="/tags/deep-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Deep Learning</span>
        </a>
    
        <a href="/tags/ntu-ml-2021/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU ML 2021</span>
        </a>
    
    
</h3>

                        </blockquote>
                    </div>
                	
                
                <br />
            </div>
            

            <div class="layui-card single-card">
                <h2 class="single-title">- Recent Posts -</h2>
            
                
                <div style="margin-left: 10px;">
                    <blockquote class="self-elem-quote self-elem-quote-bg-red" style="background-color:#FFFFFF;margin-top: 10px;">
                    <a href="/post/orbslam2-code-5/">
                        <h3 class="">ORBSLAM2 程式碼解析 - KeyFrame</h3>
                    </a>
                    <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>2021-05-01</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/orbslam2-%e7%a8%8b%e5%bc%8f%e7%a2%bc%e8%a7%a3%e6%9e%90/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">ORBSLAM2 程式碼解析</span>
        </a>
    

    
    <i class="layui-icon layui-icon-tabs" style="font-size: 22px; vertical-align: 1px;margin-right:2px;"></i>
    

    
        <a href="/tags/orbslam2/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">ORBSLAM2</span>
        </a>
    
        <a href="/tags/code-analysis/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">code analysis</span>
        </a>
    
    
</h3>

                    </blockquote>
                </div>
                
                <div style="margin-left: 10px;">
                    <blockquote class="self-elem-quote self-elem-quote-bg-red" style="background-color:#FFFFFF;margin-top: 10px;">
                    <a href="/post/ntuml-week10/">
                        <h3 class="">NTU - 機器學習 Week 10 - Auto-Encoder</h3>
                    </a>
                    <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>2021-05-01</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/ntu-%e6%a9%9f%e5%99%a8%e5%ad%b8%e7%bf%92-note/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU 機器學習 note</span>
        </a>
    

    
    <i class="layui-icon layui-icon-tabs" style="font-size: 22px; vertical-align: 1px;margin-right:2px;"></i>
    

    
        <a href="/tags/machine-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Machine Learning</span>
        </a>
    
        <a href="/tags/deep-learning/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">Deep Learning</span>
        </a>
    
        <a href="/tags/ntu-ml-2021/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">NTU ML 2021</span>
        </a>
    
    
</h3>

                    </blockquote>
                </div>
                
                <div style="margin-left: 10px;">
                    <blockquote class="self-elem-quote self-elem-quote-bg-red" style="background-color:#FFFFFF;margin-top: 10px;">
                    <a href="/post/orbslam2-code-4/">
                        <h3 class="">ORBSLAM2 程式碼解析 - Frame</h3>
                    </a>
                    <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>2021-04-28</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/orbslam2-%e7%a8%8b%e5%bc%8f%e7%a2%bc%e8%a7%a3%e6%9e%90/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">ORBSLAM2 程式碼解析</span>
        </a>
    

    
    <i class="layui-icon layui-icon-tabs" style="font-size: 22px; vertical-align: 1px;margin-right:2px;"></i>
    

    
        <a href="/tags/orbslam2/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">ORBSLAM2</span>
        </a>
    
        <a href="/tags/code-analysis/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">code analysis</span>
        </a>
    
    
</h3>

                    </blockquote>
                </div>
                
                <div style="margin-left: 10px;">
                    <blockquote class="self-elem-quote self-elem-quote-bg-red" style="background-color:#FFFFFF;margin-top: 10px;">
                    <a href="/post/orbslam2-code-3/">
                        <h3 class="">ORBSLAM2 程式碼解析 - MapPoint</h3>
                    </a>
                    <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>2021-04-28</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/orbslam2-%e7%a8%8b%e5%bc%8f%e7%a2%bc%e8%a7%a3%e6%9e%90/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">ORBSLAM2 程式碼解析</span>
        </a>
    

    
    <i class="layui-icon layui-icon-tabs" style="font-size: 22px; vertical-align: 1px;margin-right:2px;"></i>
    

    
        <a href="/tags/orbslam2/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">ORBSLAM2</span>
        </a>
    
        <a href="/tags/code-analysis/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">code analysis</span>
        </a>
    
    
</h3>

                    </blockquote>
                </div>
                
                <div style="margin-left: 10px;">
                    <blockquote class="self-elem-quote self-elem-quote-bg-red" style="background-color:#FFFFFF;margin-top: 10px;">
                    <a href="/post/orbslam2-code-2/">
                        <h3 class="">ORBSLAM2 程式碼解析 - 系統流程</h3>
                    </a>
                    <h3 style="margin-top:10px; margin-bottom:10px"> 
    <i class="layui-icon layui-icon-date" style="font-size: 28px; vertical-align: -2px;"></i>
    <span>2021-04-27</span>

    
     
    <i class="layui-icon layui-icon-list" style="font-size: 32px; vertical-align: -3px;"></i>
    

    
        <a href="/categories/orbslam2-%e7%a8%8b%e5%bc%8f%e7%a2%bc%e8%a7%a3%e6%9e%90/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">ORBSLAM2 程式碼解析</span>
        </a>
    

    
    <i class="layui-icon layui-icon-tabs" style="font-size: 22px; vertical-align: 1px;margin-right:2px;"></i>
    

    
        <a href="/tags/orbslam2/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">ORBSLAM2</span>
        </a>
    
        <a href="/tags/code-analysis/">
            <span class="layui-badge layui-bg-orange" style="vertical-align: 2px;">code analysis</span>
        </a>
    
    
</h3>

                    </blockquote>
                </div>
                
            
            <br />
            </div>
        </div>
    </div>
    
    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-WFQ2VM3C00"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-WFQ2VM3C00');
</script>
    
</div>

        </div><footer>
    

    <div class="layui-container">
        <div class="layui-row">
            <div class="layui-col-md4 layui-col-sm6 layui-col-xs6">
            </div>
        </div>
        <div class="layui-row">
            
            <div class="layui-col-md4 layui-col-sm6 layui-col-xs12">
                <a href="/zone/"><p class="footer-url">Archives</p></a>
            </div>
            
            <div class="layui-col-md4 layui-col-sm6 layui-col-xs12">
                <a href="/about/"><p class="footer-url">About</p></a>
            </div>
            
            <div class="layui-col-md4 layui-col-sm6 layui-col-xs12">
                <a href="/"><p class="footer-url">Home</p></a>
            </div>
            
        </div>
    </div>
    
    
    <div class="layui-container">
        <p class="copyright">&copy; All rights reserved. Powered by <a href='https://gohugo.io' style='color:#FFFFFF'>Hugo</a> and <a href='https://github.com/ertuil/erblog' style='color:#FFFFFF'>Erblog</a>.</p>
    </div>
</footer>

</body>
</html>
